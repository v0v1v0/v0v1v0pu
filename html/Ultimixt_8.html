<div class="container">

<table style="width: 100%;"><tr>
<td>Ultimixt-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
set of R functions for estimating the parameters of mixture distribution with a Bayesian non-informative
prior
</h2>

<h3>Description</h3>

<p>Despite a comprehensive literature on estimating mixtures of Gaussian distributions, there does not exist a
well-accepted reference Bayesian approach to such models. One reason for the difficulty is the general prohibition
against using improper priors (Fruhwirth-Schnatter, 2006) due to the ill-posed nature of such statistical objects.
Kamary, Lee and Robert (2017) took advantage of a mean-variance reparametrisation of a Gaussian mixture model to propose
improper but valid reference priors in this setting. This R package implements the proposal and computes posterior
estimates of the parameters of a Gaussian mixture distribution. The approach applies with an arbitrary number of
components. The Ultimixt R package contains an MCMC algorithm function and further functions for
summarizing and plotting posterior estimates of the model parameters for any number of components. 
</p>


<h3>Details</h3>


<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> Ultimixt</td>
</tr>
<tr>
<td style="text-align: left;">
Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
Version: </td>
<td style="text-align: left;"> 2.1</td>
</tr>
<tr>
<td style="text-align: left;">
Date: </td>
<td style="text-align: left;"> 2017-03-07</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;"> GPL (&gt;=2.0)</td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<p>Beyond simulating MCMC samples from the posterior distribution of the Gaussian mixture model, this package also produces
summaries of the  MCMC outputs through numerical and graphical methods. 
</p>
<p>Note:  The proposed parameterisation of the Gaussian mixture distribution is given by 
</p>
<p style="text-align: center;"><code class="reqn">
f(x| \mu, \sigma , {\bf p}, \varphi, {\bf \varpi, \xi})=\sum_{i=1}^k p_i f\left(x| \mu + \sigma \gamma_i/\sqrt{p_i}, \sigma \eta_i/\sqrt{p_i}\right)
</code>
</p>

<p>under the non-informative prior <code class="reqn">\pi(\mu, \sigma)=1/\sigma</code>. Here, the vector of the <code class="reqn">\gamma_i=\varphi
\Psi_i\Big({\bf \varpi}, {\bf p}\Big)_i</code>'s belongs to an hypersphere of radius <code class="reqn">\varphi</code> intersecting with an
hyperplane.  It is thus expressed in terms of spherical coordinates within that hyperplane that depend on <code class="reqn">k-2</code>
angular coordinates <code class="reqn">\varpi_i</code>. Similarly, the vector of <code class="reqn">\eta_i=\sqrt{1-\varphi^2}\Psi_i\Big({\bf
\xi}\Big)_i</code>'s can be turned
into a spherical coordinate in a k-dimensional Euclidean space, involving a radial coordinate
<code class="reqn">\sqrt{1-\varphi^2}</code> and <code class="reqn">k-1</code> angular coordinates <code class="reqn">\xi_i</code>. A natural prior for <code class="reqn">\varpi</code> is made of uniforms, <code class="reqn">\varpi_1, \ldots, \varpi_{k-3}\sim U[0, \pi]</code> and <code class="reqn">\varpi_{k-2} \sim U[0, 2\pi]</code>, and for <code class="reqn">\varphi</code>, we consider a beta prior <code class="reqn">Beta(\alpha, \alpha)</code>. A reference prior on the angles <code class="reqn">\xi</code> is <code class="reqn">(\xi_1, \ldots, \xi_{k-1})\sim U[0, \pi/2]^{k-1}</code> and a Dirichlet prior <code class="reqn">Dir(\alpha_0, \ldots, \alpha_0)</code> is assigned to the weights <code class="reqn">p_1, \ldots, p_k</code>. 
</p>
<p>For a Poisson mixture, we consider 
</p>
<p style="text-align: center;"><code class="reqn">
f(x|\lambda_1, \ldots, \lambda_k)=\frac{1}{x!}\sum_{i=1}^k p_i \lambda_i^x e^{-\lambda_i}
</code>
</p>

<p>with a reparameterisation as <code class="reqn">\lambda=\bf{E}[X]</code> and <code class="reqn">\lambda_i=\lambda
\gamma_i/p_i</code>. In this case, we can use the equivalent to the Jeffreys prior for the Poisson
distribution, namely, <code class="reqn">\pi(\lambda)=1/\lambda</code>, since it leads to a
well-defined posterior with a single positive observation. 
</p>


<h3>Author(s)</h3>

<p>Kaniav Kamary
</p>
<p>Maintainer: <a href="mailto:kamary@ceremade.dauphine.fr">kamary@ceremade.dauphine.fr</a>
</p>


<h3>References</h3>

<p>Fruhwirth-Schnatter, S. (2006). Finite Mixture and Markov Switching Models. Springer-Verlag, New York, New York. 
</p>
<p>Kamary, K., Lee, J.Y., and Robert, C.P. (2017) Weakly informative reparameterisation for location-scale mixtures. arXiv.
</p>


<h3>See Also</h3>

<p><code>Ultimixt</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">	#K.MixReparametrized(faithful[,2], k=2, alpha0=.5, alpha=.5, Nsim=10000)
</code></pre>


</div>