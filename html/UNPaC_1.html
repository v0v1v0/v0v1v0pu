<div class="container">

<table style="width: 100%;"><tr>
<td>UNPaC_Copula</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Unimodal Non-Parametric Cluster (UNPaC) Significance Test</h2>

<h3>Description</h3>

<p>The UnPAC test assesses the significance of clusters by comparing the cluster index (CI) from the data to the CI from a ortho-unimodal reference data generated using a Gaussian copula.
This method is described in Helgeson, Vock, and Bair (2021).
The CI is defined to be the sum of the
within-cluster sum of squares about the cluster means divided by the total sum of squares. Smaller values of the
CI indicate a stronger clustering.
</p>


<h3>Usage</h3>

<pre><code class="language-R">UNPaC_Copula(
  x,
  cluster,
  cluster.fun,
  nsim = 100,
  var_selection = FALSE,
  gamma = 0.1,
  p.adjust = "fdr",
  k = 2,
  rho = 0.02,
  cov = "glasso",
  center = TRUE,
  scale = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a dataset with n observations (rows) and p features (columns)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster</code></td>
<td>
<p>labels generated by clustering method</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster.fun</code></td>
<td>
<p>function used to cluster data. Function should return list containing a component "cluster."
Examples include <code>kmeans</code> and  <code>pam</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsim</code></td>
<td>
<p>a numeric value specifying the number of unimodal reference distributions used for testing
(default=100)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var_selection</code></td>
<td>
<p>should dimension be reduced using feature filtering procedure? See description below. (default=FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>threshold for feature filtering procedure. See description below. Not used if var_selection=FALSE (default=0.10)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.adjust</code></td>
<td>
<p>p-value adjustment method for additional feature filtering. See <code>p.adjust</code>
for options. (default="fdr"). Not used if p.adjust="none."</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>integer value specifying the number of clusters to test (default=2)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rho</code></td>
<td>
<p>a regularization parameter used in implementation of the graphical lasso. See documentation for lambda in
<code>huge</code>.
Not used if <code>cov="est"</code> or <code>cov="banded"</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov</code></td>
<td>
<p>method used for approximating the covariance structure.  options include: "glasso"
(See <code>huge</code>), "banded"  (See <code>band.chol.cv</code>) and
"est" (default = "glasso")</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>should data be centered such that each feature has mean equal to zero prior to clustering
(default=TRUE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>should data be scaled such that each feature has variance equal to one prior to clustering
(default=FALSE)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>There are three options for the covariance matrix used in generating the Gaussian
copula: sample covariance estimation, <code>cov="est"</code>, which should be used if n&gt;p; the graphical lasso,
<code>cov="glasso"</code>, which should be used if n&lt;p; and  k-banded covariance, <code>cov="banded"</code>, which can be used if n&lt;p and it can be assumed that
features farther away in the ordering have weaker covariance. The graphical lasso is implemented using the <code>huge</code> function.
When <code>cov="banded"</code> is selected the k-banded covariance Cholesky factor of Rothman, Levina, and Zhu (2010) is used to estimate the covariance matrix.
Cross-validation is used for selecting the banding parameter. See documentation in <code>band.chol.cv</code>.
</p>
<p>In high dimensional (n&lt;p) settings a dimension reduction step can be implemented which selects features
based on an F-test for difference in means across clusters. Features having a p-value less than a threshold
<code>gamma</code> are retained. For additional feature filtering a p-value adjustment procedure (such as p.adjust="fdr")
can be used. If no features are retained the resulting p-value for the cluster significance test is given as 1.
</p>


<h3>Value</h3>

<p>The function returns a list with the following components:
</p>

<ul>
<li>
<p><code>selected_features</code>: A vector of integers indicating the features retained by the feature filtering process.
</p>
</li>
<li>
<p><code>sim_CI</code>: vector containing the cluster indices for each generated unimodal reference distribution
</p>
</li>
<li>
<p><code>pvalue_emp</code>: the empirical p-value:  the proportion of times the cluster index from the reference
data is smaller the cluster index from the observed data
</p>
</li>
<li>
<p><code>pvalue_norm</code>: the normalized p-value: the simulated p-value based on comparison to a standard normal distribution 
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Erika S. Helgeson, David Vock, Eric Bair
</p>


<h3>References</h3>


<ul>
<li>
<p> Helgeson, ES, Vock, DM, and Bair, E. (2021) “Nonparametric cluster significance testing with reference to a unimodal null distribution."
Biometrics 77: 1215– 1226. &lt; https://doi.org/10.1111/biom.13376 &gt;
</p>
</li>
<li>
<p> Rothman, A. J., Levina, E., and Zhu, J. (2010). “A new approach to Cholesky-based covariance regularization in
high dimensions." Biometrika 97(3): 539-550.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R"># K-means example
test1 &lt;- matrix(rnorm(100*50), nrow=100, ncol=50)
test1[1:30,1:50] &lt;- rnorm(30*50, 2)
test.data&lt;-scale(test1,scale=FALSE,center=TRUE)
cluster&lt;-kmeans(test.data,2)$cluster
UNPaCResults &lt;- UNPaC_Copula(test.data,cluster,kmeans, nsim=100,cov="est")

# Hierarchical clustering example
 
test &lt;- matrix(nrow=1200, ncol=75)
theta &lt;- rep(NA, 1200)
theta[1:500] &lt;- runif(500, 0, pi)
theta[501:1200] &lt;- runif(700, pi, 2*pi)
test[1:500,seq(from=2,to=50,by=2)] &lt;- -2+5*sin(theta[1:500])
test[501:1200,seq(from=2,to=50,by=2)] &lt;- 5*sin(theta[501:1200])
test[1:500,seq(from=1,to=49,by=2)] &lt;- 5+5*cos(theta[1:500])
test[501:1200,seq(from=1,to=49,by=2)] &lt;- 5*cos(theta[501:1200])
test[,1:50] &lt;- test[,1:50] + rnorm(50*1200, 0, 0.2)
test[,51:75] &lt;- rnorm(25*1200, 0, 1)
test.data&lt;-scale(test,center=TRUE,scale=FALSE)
# Defining clustering function
hclustFunction&lt;-function(x,k){
 D&lt;-stats::dist(x)
 xn.hc &lt;- hclust(D, method="single")
 list(cluster=cutree(xn.hc, k))}

cluster=hclustFunction(test.data,2)$cluster
UNPaCResults &lt;- UNPaC_Copula(test.data,cluster,hclustFunction, nsim=100,cov="est")

</code></pre>


</div>