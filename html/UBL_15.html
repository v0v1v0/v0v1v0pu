<div class="container">

<table style="width: 100%;"><tr>
<td>NCLClassif</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Neighborhood Cleaning Rule (NCL) algorithm for multiclass imbalanced problems
</h2>

<h3>Description</h3>

<p>This function handles imbalanced classification problems using the Neighborhood Cleaning Rule (NCL) method. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">NCLClassif(form, dat, k = 3, dist = "Euclidean", p = 2, Cl = "smaller")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>form</code></td>
<td>

<p>A formula describing the prediction problem.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dat</code></td>
<td>

<p>A data frame containing the original imbalanced data set.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>

<p>A number indicating the number of nearest neighbors to use.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dist</code></td>
<td>

<p>A character string indicating which distance metric to use when determining the k nearest neighbors.  See the details. Defaults to "Euclidean".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>

<p>A number indicating the value of p if the "p-norm" distance is chosen. Only necessary to define if a "p-norm" is chosen in the <code>dist</code> argument. See details.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Cl</code></td>
<td>

<p>A character vector indicating which classes should be under-sampled. Defaults to "smaller" meaning that all "smaller"" classes are the most important and therefore only examples from the remaining classes should be removed. The user may define a subset of the existing classes in which this technique will be applied.
</p>
</td>
</tr>
</table>
<h3>Details</h3>


<dl>
<dt>
<code>dist</code> parameter:</dt>
<dd>
<p>The parameter <code>dist</code> allows the user to define the distance metric to be used in the neighbors computation. Although the default is the Euclidean distance, other metrics are available. This allows the computation of distances in data sets with, for instance, both nominal and numeric features. The options available for the distance functions are as follows: 
</p>
<p>- for data with only numeric features: "Manhattan", "Euclidean", "Canberra", "Chebyshev", "p-norm";
</p>
<p>- for data with only nominal features: "Overlap";
</p>
<p>- for dealing with both nominal and numeric features: "HEOM", "HVDM".
</p>
<p>When the "p-norm" is selected for the <code>dist</code> parameter, it is also necessary to define the value of parameter <code>p</code>. The value of parameter <code>p</code> sets which "p-norm" will be used. For instance, if <code>p</code> is set to 1, the "1-norm" (or Manhattan distance) is used, and if <code>p</code> is set to 2, the "2-norm" (or Euclidean distance) is applied.
For more details regarding the distance functions implemented in UBL package please see the package vignettes.
</p>
</dd>
<dt>NCL algorithm:</dt>
<dd>
<p>The NCL algorithm includes two phases. In the first phase the ENN algorithm is used to under-sample the examples whose class label is not in Cl. Then, a second step is performed which aims at further clean the neighborhood of the examples in Cl. To achieve this, the k nearest neighbors of examples in Cl are scanned. An example is removed if all the previous neighbors have a class label which is not in Cl, and if the example belongs to a class which is larger than half of the smaller class in Cl. In either steps the examples with class labels in Cl are always maintained.
</p>
</dd>
</dl>
<h3>Value</h3>

<p>The function returns a data frame with
the new data set resulting from the application of the NCL
algorithm. 
</p>


<h3>Author(s)</h3>

<p> Paula Branco <a href="mailto:paobranco@gmail.com">paobranco@gmail.com</a>, Rita Ribeiro
<a href="mailto:rpribeiro@dcc.fc.up.pt">rpribeiro@dcc.fc.up.pt</a> and Luis Torgo <a href="mailto:ltorgo@dcc.fc.up.pt">ltorgo@dcc.fc.up.pt</a> </p>


<h3>References</h3>

<p>J. Laurikkala. (2001). <em>Improving identification of difficult small classes by balancing class distribution</em>. Artificial Intelligence in Medicine, pages 63-66.
</p>


<h3>See Also</h3>

<p><code>ENNClassif</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># generate a small imbalanced data set
ir &lt;- iris[-c(90:135), ]
# apply NCL method with different metrics, number of neighbors and classes
ir.M1 &lt;- NCLClassif(Species~., ir, k = 3, dist = "Manhattan", Cl = "smaller")
ir.Def &lt;- NCLClassif(Species~., ir)
ir.Ch &lt;- NCLClassif(Species~., ir, k = 7, dist = "Chebyshev", Cl = "virginica")
ir.Eu &lt;- NCLClassif(Species~., ir, k = 5, Cl = c("versicolor", "virginica"))
# check the results
summary(ir$Species)
summary(ir.M1$Species)
summary(ir.Def$Species)
summary(ir.Ch$Species)
summary(ir.Eu$Species)
</code></pre>


</div>