<div class="container">

<table style="width: 100%;"><tr>
<td>UNCOVER</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Utilising Normalisation Constant Optimisation Via Edge Removal</h2>

<h3>Description</h3>

<p>Generates cohorts for a data set through removal of edges from
a graphical representation of the co-variates. Edges are removed (or
reintroduced) by considering the normalisation constant (or Bayesian
evidence) of a multiplicative Bayesian logistic regression model.
</p>
<p>The first stage of the function is concerned purely with a greedy
optimisation of the Bayesian evidence through edge manipulation. The second
stage then addresses any other criteria (known as deforestation conditions)
expressed by the user through reintroduction of edges.
</p>


<h3>Usage</h3>

<pre><code class="language-R">UNCOVER(
  X,
  y,
  mst_var = NULL,
  options = UNCOVER.opts(),
  stop_criterion = 5,
  deforest_criterion = "None",
  prior_mean = rep(0, ncol(X) + 1),
  prior_var = diag(ncol(X) + 1),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Co-variate matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Binary response vector</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mst_var</code></td>
<td>
<p>A vector specifying which variables of the co-variate matrix
will be used to form the graph. If not specified all variables will be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>options</code></td>
<td>
<p>Additional arguments that can be specified for <code>UNCOVER</code>.
See <code>UNCOVER.opts()</code> for details. Can be ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stop_criterion</code></td>
<td>
<p>What is the maximum number of clusters allowed before
we terminate the first stage and begin deforestation. Defaults to 5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deforest_criterion</code></td>
<td>
<p>Constraint type which the final model must satisfy.
Can be one of <code>"NoC"</code>, <code>"SoC"</code>, <code>"MaxReg"</code>, <code>"Validation"</code>, <code>"Diverse"</code> or
<code>"None"</code>. See details. Defaults to <code>"None"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior_mean</code></td>
<td>
<p>Mean for the multivariate normal prior used in the SMC
sampler. See details. Defaults to the origin.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior_var</code></td>
<td>
<p>Variance matrix for the multivariate normal prior used in
the SMC sampler. See details. Defaults to the identity matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Do you want the progress of the algorithm to be shown?
Defaults to <code>TRUE</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Assumes a Bayesian logistic regression model for each cohort, with
the overall model being a product of these sub-models.
</p>
<p>A minimum spanning tree graph is first constructed from a subset of the
co-variates. Then at each iteration, each edge in the current graph is
checked to see if removal to split a cohort is beneficial, and then either
we selected the optimal edge to remove or we conclude it is not beneficial
to remove any more edges. At the end of each iteration we also check the set
of removed edges to see if it is beneficial to reintroduce any previously
removed edges. After this process has ended we then reintroduce edges in the
removed set specifically to meet the criteria set by the user in the most
optimal manner possible through a greedy approach. For more details see the
Emerson and Aslett (2023).
</p>
<p>The graph can be undergo deforestation to meet 6 possible criteria:
</p>

<ol>
<li> <p><code>"NoC"</code>: Number of Clusters - we specify a maximum number of clusters
(<code>options$max_K</code>) we can tolerate in the final output of the algorithm.
</p>
</li>
<li> <p><code>"SoC"</code>: Size of Clusters - we specify a minimum number of
observations (<code>options$min_size</code>) we can tolerate being assigned to a
cluster in the final output of the algorithm.
</p>
</li>
<li> <p><code>"MaxReg"</code>: Maximal Regret - we give a maximum tolerance
(<code>exp(options$reg)</code>) that we allow the Bayesian evidence to decrease by
reintroducing an edge.
</p>
</li>
<li> <p><code>"Validation"</code>: Validation Data - we split (using
<code>options$train_frac</code>) the data into training and validation data, apply the
first stage of the algorithm on the training data and the introduce the
validation data for the deforestation stage. Edges are reintroduced if they
lead to improved prediction of the validation data using the training data
model (i.e. we aim to maximise a robustness statistic).
</p>
</li>
<li> <p><code>"Diverse"</code>: Diverse Response Class Within Clusters - We specify a
minimum number of observations (<code>options$n_min_class</code>) in a cluster that
have the minority response class associated to them (the minimum response
class is determined for each cluster).
</p>
</li>
<li> <p><code>"None"</code>: No Criteria Specified - we do not go through the second
deforestation stage of the algorithm.
</p>
</li>
</ol>
<p>All deforestation criteria other than <code>"None"</code> require additional arguments
to be specified in <code>options</code>. See examples and
<code>UNCOVER.opts()</code> for more information. It is never
recommended to use anything other than
<code>UNCOVER.opts</code> to provide the <code>options</code> argument.
</p>
<p>The prior used for the UNCOVER procedure will take the form of a
multivariate normal, where the parameters can be specified directly by the
user. It is however possible to override this default prior distributional
form by specifying <code>prior.override=TRUE</code> and providing the relevant prior
functions in <code>UNCOVER.opts</code>.
</p>
<p>The diagnostic data frames will track various outputs of the UNCOVER
procedure depending on the deforestation criterion. All data frames will
contain an action (removal or addition of an edge to the graph) and the
total log Bayesian evidence of the model gained through deployment of that
action (for <code>"Validation"</code> this will be two columns, one for the training
data and one for all of the data). <code>"NoC"</code> will also track the number of
clusters, <code>"SoC"</code> will track the minimum cluster size and the number of
criterion breaking clusters, <code>"Validation"</code> will track the robustness
statistic and "<code style="white-space: pre;">⁠Diverse"⁠</code> will track the minimum minority class across all
clusters alongside the number of criterion breaking clusters.
</p>


<h3>Value</h3>

<p>An object of class <code>"UNCOVER"</code>, which is a list consisting of:
</p>

<dl>
<dt><code>Covariate_Matrix</code></dt>
<dd>
<p>The co-variate matrix provided.</p>
</dd>
<dt><code>Response_Vector</code></dt>
<dd>
<p>The binary response vector provided.</p>
</dd>
<dt><code>Minimum_Spanning_Tree_Variables</code></dt>
<dd>
<p>A vector of indices for the
co-variates used to construct the minimum spanning tree.</p>
</dd>
<dt><code>Control</code></dt>
<dd>
<p>A list of the additional arguments specified by <code>options</code>.</p>
</dd>
<dt><code>Deforestation_Criterion</code></dt>
<dd>
<p>The deforestation criterion specified.</p>
</dd>
<dt><code>Prior_Mean</code></dt>
<dd>
<p>The mean of multivariate normal prior. Meaningless if
prior is overridden in <code>options</code>.</p>
</dd>
<dt><code>Prior_Variance</code></dt>
<dd>
<p>The variance of multivariate normal prior.
Meaningless if prior is overridden in <code>options</code>.</p>
</dd>
<dt><code>Model</code></dt>
<dd>
<p>List containing; the cluster allocation of the training data,
the log Bayesian evidences of the sub-models, the final graph of the
clustered data, the number of clusters, the edges which were removed from
the graph and a diagnostics data frame (the contents of which vary depending
on the deforestation criterion).</p>
</dd>
</dl>
<p>If <code>deforest_criterion=="Validation"</code> then <code>Model</code> is instead a list of two
lists; one containing the model information for the training data
(<code>Training_Data</code>) and the other containing model information for all of the
data (<code>All_Data</code>). Diagnostic information is only included in the <code>All_Data</code>
list.
</p>


<h3>References</h3>


<ul><li>
<p> Emerson, S.R. and Aslett, L.J.M. (2023). Joint cohort and prediction
modelling through graphical structure analysis (to be released)
</p>
</li></ul>
<h3>See Also</h3>

<p><code>UNCOVER.opts()</code>, <code>print.UNCOVER()</code>, <code>predict.UNCOVER()</code>, <code>plot.UNCOVER()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">

# First we generate a co-variate matrix and binary response vector
CM &lt;- matrix(rnorm(200),100,2)
rv &lt;- sample(0:1,100,replace=TRUE)

# We can then run our algorithm to see what cohorts are selected for each
# of the different deforestation criteria
UN.none &lt;- UNCOVER(X = CM,y = rv, deforest_criterion = "None",
                   verbose = FALSE)
UN.noc &lt;- UNCOVER(X = CM,y = rv, deforest_criterion = "NoC",
                  options = UNCOVER.opts(max_K = 3), verbose = FALSE)
UN.soc &lt;- UNCOVER(X = CM,y = rv, deforest_criterion = "SoC",
                  options = UNCOVER.opts(min_size = 10), verbose = FALSE)
UN.maxreg &lt;- UNCOVER(X = CM,y = rv, deforest_criterion = "MaxReg",
                     options = UNCOVER.opts(reg = 1), verbose = FALSE)
UN.validation &lt;- UNCOVER(X = CM,y = rv, deforest_criterion = "Validation",
                         options = UNCOVER.opts(train_frac = 0.8),
                         verbose = FALSE)
UN.diverse &lt;- UNCOVER(X = CM,y = rv, deforest_criterion = "Diverse",
                       options = UNCOVER.opts(n_min_class = 2),
                       verbose = FALSE)
clu_al_mat &lt;- rbind(UN.none$Model$Cluster_Allocation,
                    UN.noc$Model$Cluster_Allocation,
                    UN.soc$Model$Cluster_Allocation,
                    UN.maxreg$Model$Cluster_Allocation,
                    UN.validation$Model$All_Data$Cluster_Allocation,
                    UN.diverse$Model$Cluster_Allocation)
# We can create a matrix where each entry shows in how many of the methods
# did the indexed observations belong to the same cluster
obs_con_mat &lt;- matrix(0,100,100)
for(i in 1:100){
for(j in 1:100){
obs_con_mat[i,j] &lt;- length(which(clu_al_mat[,i]-clu_al_mat[,j]==0))/6
obs_con_mat[j,i] &lt;- obs_con_mat[i,j]
}
}
head(obs_con_mat)

# We can also view the outputted overall Bayesian evidence of the five
# models as well
c(sum(UN.none$Model$Log_Marginal_Likelihoods),
  sum(UN.noc$Model$Log_Marginal_Likelihoods),
  sum(UN.soc$Model$Log_Marginal_Likelihoods),
  sum(UN.maxreg$Model$Log_Marginal_Likelihoods),
  sum(UN.validation$Model$All_Data$Log_Marginal_Likelihoods),
  sum(UN.diverse$Model$Log_Marginal_Likelihoods))

# If we don't assume the prior for the regression coefficients is a
# standard multivariate normal but instead a multivariate normal with
# different parameters
UN.none.2 &lt;- UNCOVER(X = CM,y = rv, deforest_criterion = "None",
                     prior_mean = rep(1,3), prior_var = 0.5*diag(3),
                     verbose = FALSE)
c(sum(UN.none$Model$Log_Marginal_Likelihoods),
  sum(UN.none.2$Model$Log_Marginal_Likelihoods))
# We can also specify a completely different prior, for example a
# multivariate independent uniform
rmviu &lt;- function(n,a,b){
return(mapply(FUN = function(min.vec,max.vec,pn){
                      stats::runif(pn,a,b)},min.vec=a,max.vec=b,
                                     MoreArgs = list(pn = n)))
}
dmviu &lt;- function(x,a,b){
for(ii in 1:ncol(x)){
  x[,ii] &lt;- dunif(x[,ii],a[ii],b[ii])
}
return(apply(x,1,prod))
}
UN.none.3 &lt;- UNCOVER(X = CM,y = rv,deforest_criterion = "None",
                     options = UNCOVER.opts(prior.override = TRUE,
                                            rprior = rmviu,
                                            dprior = dmviu,a=rep(0,3),
                                            b=rep(1,3)),verbose = FALSE)
c(sum(UN.none$Model$Log_Marginal_Likelihoods),
  sum(UN.none.2$Model$Log_Marginal_Likelihoods),
  sum(UN.none.3$Model$Log_Marginal_Likelihoods))

# We may only wish to construct our minimum spanning tree based on the first
# variable
UN.none.4 &lt;- UNCOVER(X = CM,y = rv,mst_var = 1,deforest_criterion = "None",
                     verbose = FALSE)
c(sum(UN.none$Model$Log_Marginal_Likelihoods),
  sum(UN.none.4$Model$Log_Marginal_Likelihoods))

# Increasing the stop criterion may uncover more clustering structure within
# the data, but comes with a time cost
system.time(UNCOVER(X = CM,y = rv,stop_criterion = 4,verbose = FALSE))
system.time(UNCOVER(X = CM,y = rv,stop_criterion = 6,verbose = FALSE))


</code></pre>


</div>